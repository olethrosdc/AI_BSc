{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nashpy in /home/olethros/.local/lib/python3.8/site-packages (0.0.37)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /home/olethros/.local/lib/python3.8/site-packages (from nashpy) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/olethros/.local/lib/python3.8/site-packages (from nashpy) (1.23.2)\n",
      "Requirement already satisfied: networkx>=3.0.0 in /home/olethros/.local/lib/python3.8/site-packages (from nashpy) (3.1)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install nashpy # install nashpy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nashpy as nash\n",
    "import numpy as np\n",
    "# c.f. https://nashpy.readthedocs.io/en/stable/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Rock Paper Scizors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero sum game with payoff matrices:\n",
      "\n",
      "Row player:\n",
      "[[ 0 -1  1]\n",
      " [ 1  0 -1]\n",
      " [-1  1  0]]\n",
      "\n",
      "Column player:\n",
      "[[ 0  1 -1]\n",
      " [-1  0  1]\n",
      " [ 1 -1  0]]\n",
      "Utility if first player chooses Rock and second player chooses Paper [-1  1]\n",
      "Best responses ? (False, True)\n",
      "Nash equilibrium:\n",
      "[(array([0.33333333, 0.33333333, 0.33333333]), array([0.33333333, 0.33333333, 0.33333333]))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# payoff matrix for the first player\n",
    "rock_paper_scizors_matrix = np.array([\n",
    "    #R  #P  #S\n",
    "    [0, -1, 1], # R\n",
    "    [1, 0, -1], # P\n",
    "    [-1, 1, 0]  # S\n",
    "])\n",
    "\n",
    "# The game is a two-player zero-sum game so we only need to feed the first player payoff matrix\n",
    "game = nash.Game(rock_paper_scizors_matrix)\n",
    "print(game)\n",
    "\n",
    "\n",
    "policy_a = np.array([1, 0, 0]) # probability for each action, R, P, S\n",
    "policy_b = np.array([0, 1, 0])\n",
    "# Utility for each player, if they follow the above policies\n",
    "print(\"Utility if first player chooses Rock and second player chooses Paper\", game[policy_a, policy_b])\n",
    "print(\"Best responses ?\", game.is_best_response(policy_a, policy_b))\n",
    "\n",
    "policy_a = np.ones(3, dtype=np.float32) / 3 # random policy\n",
    "# calculate the best response\n",
    "nash_eq = game.support_enumeration()\n",
    "print(\"Nash equilibrium:\")\n",
    "print(list(nash_eq)) # nash equilibrium is fully random policies for both sides (1/3 probability for each action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) A Medieval Duel (Zero-Sum Game)\n",
    "\n",
    "#### Define the following 2-player zero-sum game where:\n",
    "There is 4 actions:\n",
    "\n",
    "1. Hide\n",
    "2. Charge with a sword\n",
    "3. Shoot an arrow \n",
    "4. Scoot\n",
    "    \n",
    "#### Description:\n",
    "You engage in a fight with your opponent, which is taking place in the middle of a forest. Both of you own a bow with a couple arrows, and a sword:\n",
    "- If you hide, your opponent cannot find you, unless he is scooting.\n",
    "- Charging costs some energy, and shooting spends an arrow.\n",
    "- Scooting makes you defenseless if your opponent is charging or shooting.\n",
    "\n",
    "Goals:\n",
    "- Define the payoff (your choice) for the first player for each action, in function of the action of the opponent.\n",
    "- Construct the game matrix.\n",
    "- Compute the nash equilibriums of your game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For each action, define their payoff when the other player picks their own action \n",
    "\n",
    "\n",
    "game_matrix = np.array([\n",
    "    [...],\n",
    "    [...],\n",
    "    [...],\n",
    "    [...]\n",
    "])\n",
    "\n",
    "game = nash.Game(game_matrix)\n",
    "nash_eq = game.linear_program()\n",
    "print(\"Nash equilibrium:\")\n",
    "print(list(nash_eq))\n",
    "# Can you interpret the nash equilibrium found ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General-Sum Games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Chicken\n",
    "The Chicken Dilemma: https://en.wikipedia.org/wiki/Chicken_(game)\n",
    "\n",
    "Goal: Define the Chicken Dilemma game matrices and determine its nash equilibria for different car costs!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_matrix_1 = np.array([\n",
    "    [0, 1],\n",
    "    [-1, -c],\n",
    "])\n",
    "game_matrix_2 = np.array([\n",
    "    [0, -1],\n",
    "    [1, -c],\n",
    "])\n",
    "\n",
    "# This is a general sum game, we need to feed the two matrices for each player\n",
    "game = nash.Game(game_matrix_1, game_matrix_2)\n",
    "nash_eq = list(game.support_enumeration())\n",
    "print(nash_eq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Prisoner's Dilemma\n",
    "\n",
    "The Prisoner's Dilemma: https://en.wikipedia.org/wiki/Prisoner%27s_dilemma\n",
    "\n",
    "Goal: Define the Prisoner's Dilemma game matrices and determine its nash equilibria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Stag Hunt\n",
    "\n",
    "The Stag Hunt problem: https://en.wikipedia.org/wiki/Stag_hunt\n",
    "\n",
    "Similarly to the Prisoner's Dilemma, define the game matrix and determine its nash equilibria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41217476, 0.43437682])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.random.uniform(size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input: game matrix with form\n",
    "## game[player, p1move, p2move, .... pnmove]\n",
    "def regret_minimiser(game, lr, T):\n",
    "    n_players = game.shape[0]\n",
    "    n_actions1 = game.shape[1]\n",
    "    n_actions2 = game.shape[2]\n",
    "    actions = np.zeros([T, 2])\n",
    "    policy = [np.random.uniform(size=n_actions1), np.random.uniform(size=n_actions2)]\n",
    "    for i in range(2): policy[i] /= sum(policy[i])\n",
    "\n",
    "    reward = [0,0]\n",
    "    for t in range(T):\n",
    "        #print(policy)\n",
    "        action1 = np.random.choice(n_actions1, p = policy[0])\n",
    "        action2 = np.random.choice(n_actions2, p = policy[1])\n",
    "        for a in range(n_actions1):\n",
    "            policy[0][a] *= np.exp(lr * game[0, a, action2])\n",
    "        policy[0] /= sum(policy[0])\n",
    "        for a in range(n_actions2):\n",
    "            policy[1][a] *= np.exp(lr * game[1, action1, a])\n",
    "        policy[1] /= sum(policy[1])\n",
    "        actions[t,:] = [action1, action2]\n",
    "        reward = game[:, action1, action2]\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rock_paper_scizors_matrix = np.array([\n",
    "    #R  #P  #S\n",
    "    [0, -1, 1], # R\n",
    "    [1, 0, -1], # P\n",
    "    [-1, 1, 0]  # S\n",
    "])\n",
    "A = regret_minimiser(np.stack([rock_paper_scizors_matrix, -rock_paper_scizors_matrix]), 0.01, 10000)\n",
    "np.mean(A[0,:]==2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
