#+TITLE: AI and Society
#+AUTHOR: Christos Dimitrakakis
#+EMAIL:christos.dimitrakakis@unine.ch
#+LaTeX_HEADER: \include{preamble}
#+LaTeX_CLASS_OPTIONS: [smaller]
#+COLUMNS: %40ITEM %10BEAMER_env(Env) %9BEAMER_envargs(Env Args) %4BEAMER_col(Col) %10BEAMER_extra(Extra)
#+TAGS: activity advanced definition exercise homework project example theory code
#+OPTIONS:   H:3
#+latex_header: \AtBeginSection[]{\begin{frame}<beamer>\tableofcontents[hideothersubsections]\end{frame}}

* Humans and AI
** Safety
*** Design problems
*** Securing AI systems
1. Understand what the system can do and where it is applied.
2. You donâ€™t have to compute gradients to break an AI system.
3. AI red teaming is not safety benchmarking.
4. Automation can help cover more of the risk landscape.
5. The human element of AI red teaming is crucial.
6. Responsible AI harms are pervasive but difficult to measure.
7. LLMs amplify existing security risks and introduce new ones.
8. The work of securing AI systems will never be complete.

** Privacy
*** Data collection
*** Data publication
** Fairness
*** Goals and social welfare
*** Group fairness
