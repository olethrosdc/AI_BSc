{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Definition (Already Implemented)\n",
    "\n",
    "actions = {\n",
    "    \"up\": (0, 1),\n",
    "    \"left\": (-1, 0),\n",
    "    \"right\": (1, 0),\n",
    "    \"down\": (0, -1),\n",
    "}\n",
    "\n",
    "p_e = 1/3\n",
    "\n",
    "def get_adjacent_positions(position: Tuple[int, int]) -> List[Tuple[int, int]]:\n",
    "    x, y = position\n",
    "    return [\n",
    "            (x, y + 1),\n",
    "            (x, y - 1),\n",
    "            (x + 1, y),\n",
    "            (x - 1, y),\n",
    "    ]\n",
    "\n",
    "class DungeonEnvironment:\n",
    "    def __init__(self):\n",
    "        self.start_pos = (0,0)\n",
    "        self.goal_pos = (3,4)\n",
    "        self.holes = [(0,4), (3,2)]\n",
    "        self.walls = [(0,2), (2,0), (2,2), (2,3)]\n",
    "        self.current_position = (0,0)\n",
    "\n",
    "    def get_echo(self):\n",
    "        for adjacent in get_adjacent_positions(self.current_position):\n",
    "            if adjacent in self.holes:\n",
    "                # hear an each with prob 1/3\n",
    "                if np.random.random() < p_e:\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Called at the start of the game.\n",
    "        \"\"\"\n",
    "        self.current_position = self.start_pos\n",
    "\n",
    "    def step(self, action: str) -> Tuple[dict, str, bool]:\n",
    "        \"\"\"\n",
    "        Updates the environment with the action of the agent.\n",
    "        :returns: new observation for the agent, as well as if the game ended and the outcome.\n",
    "        \"\"\"\n",
    "        act_x, act_y = actions[action]\n",
    "        curr_x, curr_y = self.current_position\n",
    "\n",
    "        new_x = curr_x + act_x\n",
    "        new_y = curr_y + act_y\n",
    "\n",
    "        # we bump if we go into a wall, or if we go out of bound\n",
    "        if (new_x, new_y) in self.walls or not (0<=new_x<=4 and 0<=new_y<=4):\n",
    "            bump = True\n",
    "        else:\n",
    "            # if we do not bump, update the position.\n",
    "            bump = False\n",
    "            self.current_position = (new_x, new_y)\n",
    "\n",
    "        observation = {\n",
    "            \"echo\" : self.get_echo(),\n",
    "            \"position\": self.current_position,\n",
    "        }\n",
    "\n",
    "        if self.current_position == self.goal_pos:\n",
    "            outcome = \"Escaped\"\n",
    "            terminated = True\n",
    "        elif self.current_position in self.holes:\n",
    "            outcome = \"Fell into hole\"\n",
    "            terminated = True\n",
    "\n",
    "        else:\n",
    "            outcome = None\n",
    "            terminated = False\n",
    "\n",
    "        return observation, outcome, terminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Belief State (To be completed)\n",
    "\n",
    "\n",
    "class BeliefState:\n",
    "    \"\"\"\n",
    "    Maintains what we believe, using the knowledge base.\n",
    "    \"\"\"\n",
    "    def __init__(self, initial_hole_prob=0.1):\n",
    "        self.initial_hole_prob=initial_hole_prob # initial belief for holes\n",
    "        self.hole_probabilities = {}  # list of positions where we sensed echoes\n",
    "        self.current_position = (0, 0)\n",
    "        \n",
    "        for x in range(-1, 6):\n",
    "            for y in range(-1, 6):\n",
    "                self.hole_probabilities[(x,y)] = self.initial_hole_prob\n",
    "                \n",
    "    def k_hole_probability(self, position: Tuple[int, int], k: int) -> float:\n",
    "        \"\"\"\n",
    "        Probability of being adjacent to k holes, using our belief\n",
    "        \"\"\"\n",
    "        # We should look into all the possibilities about the adjacent 4 tiles (hole or no hole)\n",
    "        \n",
    "        # TODO\n",
    "        pass\n",
    "    \n",
    "    def k_hole_probability_knowing_hole(self, position: Tuple[int, int], k: int, known_hole_pos: Tuple[int, int]) -> float:\n",
    "        \"\"\"\n",
    "        Probability of being adjacent to k holes, knowing that there is one hole at \"known_hole_pos\".\n",
    "        \"\"\"\n",
    "        # Same as k_hole_probability(), but we know that one of the adjacent positions has a hole.\n",
    "            \n",
    "        # TODO\n",
    "        pass\n",
    "    \n",
    "    def echo_probability(self, position: Tuple[int, int]) -> float:\n",
    "        \"\"\"\n",
    "        Probability of hearing an echo at this position, basing ourselves of our belief\n",
    "        \"\"\"\n",
    "        # Using k_hole_probability(), we can compute the probability of hearing an echo, considering all possibilities:\n",
    "        # 1, 2, 3, or 4 holes could be adjacent to us.\n",
    "            \n",
    "        # TODO\n",
    "        pass\n",
    "    \n",
    "    def echo_probability_knowing_hole(self, position: Tuple[int, int], known_hole_pos: Tuple[int, int]):\n",
    "        \"\"\"\n",
    "        Probability of hearing an echo at this position, knowing the position of a hole\n",
    "        \"\"\"\n",
    "        # Same as echo_probability(). Since we know the position of a hole, we can use k_hole_probability_knowing_hole() instead.\n",
    "            \n",
    "        # TODO\n",
    "        pass\n",
    "    \n",
    "\n",
    "    def update(self, echo: bool, position: Tuple[int, int]):\n",
    "        \"\"\"\n",
    "        :param echo: did we hear an echo ?\n",
    "        :param position: our current position.\n",
    "        \"\"\"\n",
    "        self.current_position = position\n",
    "        \n",
    "\n",
    "                \n",
    "        new_belief = self.hole_probabilities.copy()\n",
    "        \n",
    "        \n",
    "        for hole_pos in get_adjacent_positions(position):\n",
    "            echo_prob = self.echo_probability(position)\n",
    "            echo_prob_knowing_hole = self.echo_probability_knowing_hole(position, hole_pos)\n",
    "                    \n",
    "            # Update the belief using Baye's theorem.\n",
    "            if echo:\n",
    "                new_belief[hole_pos] = ... # TODO\n",
    "            else:\n",
    "                new_belief[hole_pos] = ... # TODO\n",
    "                \n",
    "        self.hole_probabilities = new_belief\n",
    "        \n",
    "        \n",
    "    def visualise(self):\n",
    "        grid_size = (7, 7)\n",
    "        grid = np.zeros(grid_size)\n",
    "\n",
    "        for (x, y), p in self.hole_probabilities.items():\n",
    "            grid[y + 1, x + 1] = p\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(grid, cmap=\"viridis\", origin=\"lower\", extent=[-1, 6, -1, 6])\n",
    "\n",
    "        plt.colorbar(label=\"Hole probability\")\n",
    "        plt.xlabel(\"x\")\n",
    "        plt.ylabel(\"y\")\n",
    "        plt.xticks(range(-1, 7))\n",
    "        plt.yticks(range(-1, 7))\n",
    "        plt.grid(True, linestyle=\"--\", alpha=0.6, color=\"black\")\n",
    "        plt.title(\"Holes belief\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for running any agent on the dungeon environment (Already implemented)\n",
    "def play_game(policy, belief_state):\n",
    "    terminated = False\n",
    "    environment = DungeonEnvironment()\n",
    "    environment.reset()\n",
    "    num_steps = 0\n",
    "    trajectory = []\n",
    "    while not terminated:\n",
    "        action = policy(belief_state)\n",
    "        observation, outcome, terminated = environment.step(action)\n",
    "        belief_state.update(**observation)\n",
    "        trajectory.append(environment.current_position)\n",
    "        num_steps += 1\n",
    "\n",
    "        if num_steps >= 500:\n",
    "            print(\"Check your code, probably your agent is stuck somewhere\")\n",
    "            outcome = \"Timeout\"\n",
    "            terminated = True\n",
    "    \n",
    "    return outcome, trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent definitions\n",
    "\n",
    "# Naive agent Example \n",
    "def random_agent(belief) -> str:\n",
    "    \"\"\"\n",
    "    This is a naive agent, picking actions randomly.\n",
    "    \"\"\"\n",
    "    action_names = list(actions.keys())\n",
    "    return np.random.choice(action_names)\n",
    "\n",
    "\n",
    "def smarter_agent(belief) -> str:\n",
    "    \"\"\"\n",
    "    This function selects a new action based on the belief state.\n",
    "    :param belief: Current belief state.\n",
    "    :return: action picked by the policy (e.g., \"up\"):\n",
    "    \"\"\"\n",
    "    # TODO (optional): try implementing a smarter agent\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "belief_state = BeliefState()\n",
    "\n",
    "print(\"Initial belief:\")\n",
    "belief_state.visualise()\n",
    "\n",
    "for episode in range(1, 101):\n",
    "    outcome, trajectory = play_game(random_agent, belief_state)\n",
    "    \n",
    "    print(f\"Episode {episode}:\")\n",
    "    print(f\"The game ended in {len(trajectory)} steps with the following outcome: {outcome}.\")\n",
    "    \n",
    "    if episode % 10 == 0:\n",
    "        print(\"Belief:\")\n",
    "        belief_state.visualise()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
