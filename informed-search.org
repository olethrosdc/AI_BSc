#+TITLE: Informed search
#+AUTHOR: Christos Dimitrakakis
#+EMAIL:christos.dimitrakakis@unine.ch
#+LaTeX_HEADER: \input{preamble}
#+LaTeX_CLASS_OPTIONS: [smaller]
#+COLUMNS: %40ITEM %10BEAMER_env(Env) %9BEAMER_envargs(Env Args) %4BEAMER_col(Col) %10BEAMER_extra(Extra)
#+TAGS: activity advanced definition exercise homework project example theory code
#+OPTIONS:   H:3
* The Shortest Path Problem
** The shortest path problem
*** The costs of a path
At time $t$:
#+ATTR_BEAMER: :overlay <+->
- We are in state $s_t \in S$.
- We take some action $a_t \in A$.
- Then we pay cost $c_t = c(s_t, a_t)$ and...
- .. move to state $s_{t+1} = \trans(s_t, a_t)$.
#+BEAMER: \pause
**** The cost of a policy $\pol : S \to A$.
#+ATTR_BEAMER: :overlay <+->
- A policy $\pol$ specifies a *path* $s_1, \ldots$ with $s_{k+1} = \tau(s_k, \pi(s_k))$
- Following $\pol$ from state $s_1$ has a total *cost* $C^\pi(x_1) \defn \sum_{k=1}^{t} c(x_k, \pi(x_k))$.
#+BEAMER: \pause
**** The cost of a path (alternative)
#+ATTR_BEAMER: :overlay <+->
- We can instead use costs for going from state $x$ to state $y$:  $c(\langle x,y \rangle)$.
- Following a *path* $h$ has a total cost $C(h) \defn \sum_{\langle x,y \rangle \in h} c(\langle x,y \rangle)$


*** The shortest path problem
**** Input: 
#+ATTR_BEAMER: :overlay <+->
- State space $S$.
- *transition* function $\trans : S \times A \to S$.
- *start* states $X \subset S$
- *goal* states $Y \subset S$
- *costs* $c: S \times A \to \Reals$

#+BEAMER: \pause
**** Output 
#+ATTR_BEAMER: :overlay <+->
Either:
- Find a path $h$ from $X$ to $Y$ so that $C(h) \leq C(h')$ for all $h'$
- Find a policy $\pol : S \to A$ that finds a shortest path for every starting state.

#+BEAMER: \pause
**** Notes
- If the path/policy does not reach a goal, the cost is infinite.
- We can maximise rewards instead of minimising costs.

  
*** Formalising the shortest path problem
The cost from state $s$ of a policy that reaches a goal in $Y$ is
\[
C^\pi(s) \defn \sum_{i=1}^\infty c[s_{t}, \pi(s_t)], \qquad s_{t+1} = \tau[s_t, \pi(s_t)], \quad s_{1} = s
\]
where for every $y \in Y$,  $c(s, a) = 0$ and $\tau(y,a) = y$ for all actions.
#+BEAMER: \pause
- We can calculate this recursively:
\begin{align}
C^\pi(s)
\uncover<2->{
& = \sum_{i=1}^\infty c[s_{t}, \pi(s_t)]\\
}
\uncover<3->{
& = c[s, \pi(s)] + \sum_{i=2}^\infty c[s_{t}, \pi(s_t)]\\
}
\uncover<4->{
& = c[s, \pi(s)] + C^\pi\{\tau[s, \pi(s)]\}.
}
\end{align}
#+BEAMER: \pause
#+BEAMER: \pause
#+BEAMER: \pause
- The same idea applies for the *shortest* path
\begin{align}
C^*(s) 
\defn \min_\pi C^\pi(s)
= \min_a \left\{c[s, a] + C^*[\tau(s, a)]\right\}.
\end{align}

*** Dijkstra's shortest path algorithm: backward search
**** Shortest path algorithm
\begin{algorithmic}
\STATE Input: Goal states $Y$, starting state $x$.
\STATE Set $C(s) = 0$ for $s \in Y$, $C(s) = \infty$ for $s \notin Y$, $F_0 = Y$
\FOR {$t = 0, 1, \ldots$}
\STATE $s_t = \argmin_{s \in F_t} C(s)$
\FOR {$s \in \parent(s_t)$}
\STATE $\pol(s) = \argmin_a c(s,a) + C(\tau(s, a))$
\STATE $C(s) = \min_a c(s,a) + C(\tau(s, a))$
\ENDFOR
\STATE $F_{t+1} = F_t \setminus \{s_t\} \cup \parent(s_t)$
\IF {$F_{t+1} = \emptyset$ or $x \in F_t$}
\RETURN $\pol, C$
\ENDIF
\ENDFOR
\end{algorithmic}
**** Algorithm idea
- Start from goal states
- Go back one step each time, adding the cost.
- Stop whenever there are no more states to go back to, or if we reach the start state.

*** Optimality proof
**** Theorem
$C(s) = C^*(s)$
#+BEAMER: \pause
**** Proof
#+ATTR_BEAMER: :overlay <+->
- If $s \in Y$, then $C(s) = 0 = C^*(s)$.
- For any other $s', s = \parent(s')$: we will show that:
 if $C(s') \leq C^*(s')$ then $C(s) \leq C^*(s)$.
\begin{align*}
\uncover<3->{
C(s)
&=
\min_a \left\{c(s,a) + C(\tau(s,a))\right\}
\tag{by definition}
\\
}
\uncover<4->{
&\leq
\min_a \left\{ c(s,a) + C^*(\tau(s,a)) \right\}
\tag{by induction}
\\
}
\uncover<5->{
&\leq
\min_a \left\{ c(s,a) + C^{\pi'}(\tau(s,a)) \right\},
\qquad \forall \pi'
\tag{by optimality}
\\
}
\uncover<6->{
&\leq
C^\pi(s), \qquad \forall \pi.
}
\end{align*}
#+BEAMER: \pause
#+BEAMER: \pause
#+BEAMER: \pause
For the optimal policy $\pi^*$, $C^{\pi^*}(s) = C^*(s)$, so $C(s) \leq C^*(s)$. Finally,
\[
C^*(s) \geq C^{\pi}(s) = C(s) \geq C^*(s),
\]
since $C^{\pi}(s) = C(s)$ for the policy returned by the algorithm.
*** Properties of Dijkstra's algorithm
- Finds an optimal path from $X$ to $Y$
- The costs along that optimal path are correct.
- Costs of any other state may be incorrect.
- This is because of the greedy step in which states are searched.
- By going through all the states again, we can calculate the minimal cost for every state.

** Heuristic Search
*** Partial graphs
- Why do we need search?
- We do not want to calculate on the whole graph
- We use *search* to find the shortest path more efficiently (perhaps).
- We denote the total cost of some path $x_1, \ldots, x_t$ as:
\[
C(x_1, \ldots, x_t)
\]
- The remaining cost from $x_t$ to the goal using some policy $\pi$ as
\[
C^\pi(x_t)
\]

*** Generic search
We define heuristic search in the context of shortest-path problems.

We now consider a general method for searching a node in the frontier.

\begin{algorithmic}
\STATE \textbf{input} $G = \langle N, E \rangle$: Graph.
\STATE \textbf{input} $f : N \to \Reals$: evaluation function.
\STATE \textbf{input} $x$ : Start node
\STATE \textbf{function} \texttt{Heuristic Search}($G, x, h$)
\STATE $S' = \emptyset$ : Nodes searched.
\STATE $F = \{x\}$. Initialise the frontier
\STATE $c_x = 0$. Initialise the cost of node $x$
\WHILE {$F \neq \emptyset$}
\STATE $n = \argmin_{i \in F} f(i)$. Select "best" node.
\STATE $F = F \setminus \{n\}$. Remove $n$ from the frontier.
\IF {$n \notin S'$}
\STATE $B = \child(n) \setminus S'$. Get the set of unsearched children of $n$.
\STATE $\forall b \in B$, $b_i = c_n + c(n,b)$. Calculate the total cost to each child $b$.
\STATE $S' = S' \cup \{n\}$. Add $n$ to the list of searched nodes.
\STATE $F = F \cup B$. Add $n$'s children to the frontier.
\ENDIF
\ENDWHILE
\end{algorithmic}

*** $A^*$ search
We now consider a general method for searching a node in the frontier.

\begin{algorithmic}
\STATE \textbf{input} $G = \langle N, E \rangle$: Graph.
\STATE \textbf{input} $h : N \to \Reals$: heuristic function.
\STATE \textbf{input} $x$ : Start node
\STATE \textbf{function} \texttt{A-Star}($G, x, h$)
\STATE $S' = \emptyset$ \# Nodes searched.
\STATE $F = \{x\}$. \# Initialise the frontier
\STATE $c_x = 0$. \# Initialise the cost of node $x$
\WHILE {$F \neq \emptyset$}
\STATE $n = \argmin_{i \in F} c_i + h(i)$. \# Select minimum cost + heuristic.
\STATE $F = F \setminus \{n\}$. \# Remove $n$ from the frontier.
\IF {$n \notin S'$}
\STATE $B = \child(n) \setminus S'$. \# Get the set of unsearched children of $n$.
\STATE $\forall b \in B$, $b_i = c_n + c(n,b)$. \# Calculate the total cost to each child $b$.
\STATE $S' = S' \cup \{n\}$. \# Add $n$ to the list of searched nodes.
\STATE $F = F \cup B$. \# Add $n$'s children to the frontier.
\ENDIF
\ENDWHILE
\end{algorithmic}

- You can see that $h = 0$ corresponds to minimum-cost search.
*** Admissible heuristics
- If $h$ is arbitrary, then the search can fail.
- We need $h$ to be admissible. In particular,
\[
C^*(n) \geq h(n).
\]
*** Admissibility of $A^*$
**** Theorem
$A^*$ returns an optimal solution if
#+ATTR_BEAMER: :overlay <+->
- The graph has a bounded branching factor.
- All costs are greater that $\epsilon > 0$
- The heuristic is admissible, i.e. $0 \leq h(n) \leq C^*(n)$ for all $n \in N$.
#+BEAMER: \pause
**** Proof
#+ATTR_BEAMER: :overlay <+->
- *Existence*. There is a finite number of paths that will be explored, as the longest possible path to a goal is $C^*(0)/\epsilon$ and the branching factor is bounded.
- *Optimality*. The proof is by contradiction. Let as assume that $A^*$ finds some $\pi \neq \pi^*$ so that $C(\pi) > C(\pi^*)$. That means that at some node $n$ on the path there is an action $a^*$ on the optimal policy, but we keep expanding the path $x_1, x_2, \ldots$ of $\pi$. However, since $C(\pi) > C(\pi^*)$ there must be some $t$ such that $C(n, x_1, \ldots, x_t) > C^{\pi^*}(n)$. But then, to expand $\pi$ requires that $C(n, x_1, \ldots, x_t) + h(x') < h(x) \leq C^{\pi^*}(n)$.

** Upper and lower bounds algorithms
*** Calculating Upper and Lower Bounds
Starting from a set of leaf nodes $S_0$
**** Upper bound  $U(s) \geq C^*(s)$ for $s \in S_0$
Setting $U(0) \geq C^*(0)$ and recursing:
\[
U(s) = \min_{a \in A_s} c(s,a) + U[\tau(s,a)]
\]
By induction, we can prove that this is an upper bound on $C^*$:
\[
U(s) = \min_{a \in A_s} c(s,a) + U[\tau(s,a)]
\geq \min_{a \in A_s} c(s,a) + C^*[\tau(s,a)]
= C^*(s). 
\]

**** Lower bound  $L(s) \leq C^*(s)$ for $s \in S_0$
\[
L(s) = \min_{a \in A_s} c(s,a) + L[\tau(s,a)]
\]
Similarly, we can prove that it is a lower bound:
\[
L(s) = \min_{a \in A_s} c(s,a) + L[\tau(s,a)]
\leq \min_{a \in A_s} c(s,a) + C^*[\tau(s,a)]
= C^*(s)
\]
*** Branch and bound
The algorithm is rather simple to describe in words.
- [1] Set $s = 0$.
- [1.1] Select action $a^*$ minimising $c(s,a) + L(\tau(s,a))$.
- [1.2] Discard subtrees $(s,a)$ for which $c(s,a) + L(\tau(s,a)) \geq c(s,a^*) + L(\tau(s,a^*))$.
- [1.3] Proceed to $s = \tau(s,a)$ and go to 1.1. unless we are at a leaf.
- [2] Expand the leaf node, and generate new leaf nodes with corresponding upper and lower bounds.
- [3] Calculate $L, S$ for the corresponding subtree.
- [4] Go to 1.

* General weight shortest path
** General weight shortest path
*** General weight shortest path
- In this problem, actions can have positive or negative costs.
- Negative edges generate problems if we have cycles
- However, the basic algorithmic idea is again Dynamic Programming
**** Bellman-Ford Algorithm
In state-action notation, the algorithm is simply
- $C_0(0) = 0$, $C_i(0) = \infty$ for all $i \neq 0$.
- For $k \in 1, \ldots, |S|$:
\[
C_{k}(s) = \min_a c(s,a) + C_{k-1}(\tau(s,a))
\]

*** Bellman-Ford Algorithm

\begin{algorithmic}
\STATE $C(0) = 0$. $C(i) = \infty$, for $i \neq 0$.
\FOR {$i \in 1, \ldots, |N| - 1$}
\FOR {all edges $(i,j)$}
\IF {$C(i) + c(i,j) < C(j)$}
\STATE $c(j) = C(i) + c(i,j)$
\ENDIF
\ENDFOR
\ENDFOR
\FOR {all edges $(i,j)$}
\IF {$C(i) + c(i,j) < C(j)$}
\STATE \textbf{error} "Negative cycle"
\ENDIF
\ENDFOR
\end{algorithmic}

- Succinctly, the algorithm is just like Dijkstra, but it ensures it goes at most $|N| - 1$ times through all vertices, and has a sanity check as no more updates should be possible at the end.
- Instead of keeping a track of explored nodes, it uses the fact that $C$ is initialised to infinity.




