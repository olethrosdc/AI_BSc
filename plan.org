#+TITLE: Artificial Intelligence
#+AUTHOR: Christos Dimitrakakis
#+EMAIL:christos.dimitrakakis@unine.ch
#+LaTeX_HEADER: \newcommand \E {\mathop{\mbox{\ensuremath{\mathbb{E}}}}\nolimits}
#+LaTeX_HEADER: \newcommand\ind[1]{\mathop{\mbox{\ensuremath{\mathbb{I}}}}\left\{#1\right\}}
#+LaTeX_HEADER: \renewcommand \Pr {\mathop{\mbox{\ensuremath{\mathbb{P}}}}\nolimits}
#+LaTeX_HEADER: \DeclareMathOperator*{\argmax}{arg\,max}
#+LaTeX_HEADER: \DeclareMathOperator*{\argmin}{arg\,min}
#+LaTeX_HEADER: \newcommand \defn {\mathrel{\triangleq}}
#+LaTeX_HEADER: \newcommand \Reals {\mathbb{R}}
#+LaTeX_HEADER: \newcommand \Param {\Theta}
#+LaTeX_HEADER: \newcommand \param {\theta}
#+TAGS: activity advanced definition exercise homework project example theory code
#+OPTIONS:   H:3

* Introduction
  
This course will focus on algorithms and models for Artificial
Intelligence.  We will concentrate mainly on the decision making,
rather than the learning, side of artificial intelligence. Learning is
already addressed in statistics courses, as well as the machine
learning course in the final year.

The philosophy of this course is as follows: 
- We give example problems.
- We use theory to explain and generalise from those examples to general problems.
- We describe algorithms to /solve/ general problems.
- We implement algorithms to solve the specific examples.

In general, the course will start from the simplest problems and
slowly progress to the more complex ones.

** What is Artificial Intelligence?

*** Decision making and interaction
- Recommend a route.
- Buy and sell stocks.
- Make a move in chess.

*** Learning.
- Decisions depend on infirmation.

  
** Methods for Artificial Intelligence
*** Optimisation and Decision Theory
**** Optimal decisions
- Problem-dependent
- Require defining a cost- or utility function
- The optimal solution has the lowest cost or maximal utility

**** Optimisation: algorithms for optimal solutions
- Discrete optimisation.
- Linear optimisation.
- Non-linear optimisation.

*** Statistics and Machine Lerning
- How to learn from data and interactions.

* Single agent problems with no uncertainty
** Elementary Decision Theory
*** Preferences
**** Types of rewards                                               :example:
- For e.g. a student: Tickets to concerts.
- For e.g. an investor: A basket of stocks, bonds and currency.
- For everybody: Money.

**** Preferences among rewards
For any rewards $x, y \in R$, we either
- (a) Prefer $x$ at least as much as $y$ and write $x \preceq^* y$.
- (b) Prefer $x$ not more than $y$ and write $x \succeq^* y$.
- (c) Prefer $x$ about the same as $y$ and write $x \eqsim^* y$.
- (d) Similarly define $\succ^*$ and $\prec^*$

*** Utility and Cost

**** Utility function
To make it easy, assign a utility $U(x)$ to every reward through a
utility function $U : R \to \Reals$.

**** Utility-derived preferences
- (a) $U(x) \geq U(y)$ $\Leftrightarrow$ $x \succ
eq^* y$
- (b) $U(x) \leq U(y)$ $\Leftrightarrow$ $x \succ
eq^* y$

** Few choices
*** Enumeration
- $\argmax_x U(x)$
#+BEGIN_SRC python
  # returns the first element maximising U
  import numpy as np
  x_star = np.argmax(U)
#+END_SRC
** Infinite choices
*** First-order gradient methods
*** Stochastic search

** Structured choices
*** The structure of choices

*** Depth-first search
*** Breath-first search
*** Dynamic programming

** Logic 
*** Knowledge base
**** Syntax and Semtantics
- Syntax: How to construct sentences
- Semantix: What sentences mean
**** Truth
- A statement $A$ is either true or false in any model $m$.
**** Model
- $M(A)$ the set of all models where $A$ is true.
**** Entailment
- $A \models B$ means that $B$ is true whenever $A$ is true.
- $A \models B$ if and only if $M(A) \subseteq M(B)$.
**** Knowledge-Base
- A set of sentences that are true.
**** Inference
- $KB \vdash_i A$: Algorithm $i$ can derive $A$ from KB.
*** Propositional logic syntax
-Sentence $\to$ Atomic | Complex
-Atomic \to True | False | A | B | C | \ldots
-Complex \to (Sentence) | [Sentence]
- | $\neg$  Sentence (not)
- | Sentence $\wedge$ Sentence (and)
- | Sentence $\vee$ Sentence (or)
- | Sentence $\Rightarrow$ Sentence (implies)
- | Sentence $\Leftrightarrow$ Sentence (if and only if)

Precedence: $\neg, \wedge, \vee, \Rightarrow, \Leftrightarrow$

*** Difference between Meta-Logic and Propositional Logic
**** Meta-Logic
- $\alpha \models \beta$: $(\alpha \Rightarrow \beta)$ in every model.
- $\alpha \equiv \beta$: $(\alpha \Leftrightarrow \beta)$ in every model.
**** Propositional Logic
- $A \Rightarrow B$: $A$ implies $B$
- $A \Leftrightarrow B$, $A$ is true iff $B$ is true.
*** Proposition logic semantics
- $A \Rightarrow B \equiv (\neg B \Rightarrow \neg A)$
- $\neg (\neg A) \equiv A$
- $(A \Rightarrow B) \equiv (\neg B \Rightarrow \neg A)$
- $(A \Rightarrow B) \equiv (\neg A \vee B)$


**** Models
A model fixes the truth value for every symbol
For any model $m$:
- $\neg P$ is true iff $P$ is false in $m$.
- $P \wedge Q$ is true iff $P, Q$ are true in $m$.
- $P \vee Q$ is true iff either $P$ or $Q$ is true in $m$.
- $P \Rightarrow Q$ is true unless $P$ is true and $Q$ is false in $m$.
- $P \Leftrightarrow Q$ if $P,Q$ are both true or both false in $m$.

**** Inference Rules
- If $a \Rightarrow b$ and $a$ is true then $b$ is true.
- If $a$ and $b$ is true then $a$ is true.
**** From set theory
- If $A \subset B$ $\omega \in A$  $\omega in B$.
- If $\omega \in A \cap B then $\omega \in A$.
*** Conjunctive Normal Forms
**** Equivalence
Every sentence is equivalent to a conjunction
*** Inference
Let's check if $KB \models A$, i.e. if what we know implies $A$.
From entailment, this means that if our $KB$ is correct, then $A$ must be true.

* Single agent problems with uncertainty
** Probability

** Satatistical Decision Theory
*** Expected utility
** Few Choices
*** Enumeration
** Structured choices
*** Policies
*** Dynamic programming
** Constrained problems
*** Constrained optimisation

* Multiple agent problems with no uncertainty
** Two-Player Zero-sum Alternating Games
*** Backwards Induction
** Two-Player Zero-sum Normal-Form Games
*** Linear Programming
** Two-Player General Games

* Optimisation methods
** Gradient Descent
$d_t = \nabla_x f(x_t)$.

** Stochastic Gradient Descent
$d_t = \nabla_x f(x_t) + \epsilon_t$.
** Newton's Method

** Simulated Annealing

** Monte-Carlo Methods
** Dynamic Programming and Backwards Induction
** Linear Programming
* Books and schedule

Artificial Intelligence: Foundations of Computational Agents, 3rd Edition
Artificial Intelligence: a Modern Approach, 4th Edition

|--------+----------------------------------+-------------------------------|
| Module | Topics                           | AI:FoCA                       |
|--------+----------------------------------+-------------------------------|
|      1 | - Preferences                    | 1. AI and Agents              |
|        | - Utility                        | 1.2. Complexity               |
|        | - States                         | 1.3. Application domains      |
|        | - Actions                        | 1.4. Knowledge representation |
|        | - Beliefs                        | 2. Architecture               |
|        | - Fairness                       | 2.1. Control                  |
|        |                                  | 2.2. Hierarchical control     |
|        |                                  | 2.3. Moral machines           |
|--------+----------------------------------+-------------------------------|
|      2 | Depth-First Search               | 3. Search                     |
|        | Breadth-First Search             | 3.1. Search in graphs         |
|        | Heuristic Search                 | 3.2. Uninformed search        |
|        | A* Search                        | 3.3. Heuristic search         |
|        |                                  |                               |
|--------+----------------------------------+-------------------------------|
|      3 | Dynamic Programming              | 3.3. Heuristic search         |
|        | Bounded Search                   | 3.4. Dynamic programming      |
|        | Branch and bound                 | 3.5. Branch and bound         |
|        |                                  |                               |
|--------+----------------------------------+-------------------------------|
|      4 | Local Search                     | 4. Reasoning with constraints |
|        |                                  |                               |
|        | Propositional Constraints        |                               |
|        |                                  |                               |
|        |                                  |                               |
|--------+----------------------------------+-------------------------------|
|        | 6.1. States, Actions, Goals      |                               |
|      4 | Deterministic Planning           | 6.2. Forward Planning         |
|        |                                  | 6.2. Regressoin Planning      |
|        |                                  | 6.4. Planning as CSP          |
|        |                                  | 6.5. Partial Order Planning   |
|--------+----------------------------------+-------------------------------|
|      5 | Stochastic Gradient              | (4.1)                         |
|        | The Perceptron                   |                               |
|--------+----------------------------------+-------------------------------|
|      6 | Probability Theory               | 12. Uncertainty               |
|        | Bayes Theorem                    | 13. Probabilistic Reasoning   |
|--------+----------------------------------+-------------------------------|
|      7 | Reading week                     |                               |
|--------+----------------------------------+-------------------------------|
|      8 | Expected Utility Theory          | 15. Making Simple Decisions   |
|--------+----------------------------------+-------------------------------|
|      9 | Markov Decision Processes        | 16. Making Complex Decisions  |
|        | Dynamic Programming              |                               |
|--------+----------------------------------+-------------------------------|
|     10 | Alternating Zero-Sum Games       | 6. Games                      |
|        | Stochastic Zero-Sum Games        |                               |
|--------+----------------------------------+-------------------------------|
|     11 | Simultaneous Move Zero-Sum Games |                               |
|        | Linear Programming               |                               |
|        | General games                    |                               |
|--------+----------------------------------+-------------------------------|
|     12 | Project Presentations            |                               |
|--------+----------------------------------+-------------------------------|



